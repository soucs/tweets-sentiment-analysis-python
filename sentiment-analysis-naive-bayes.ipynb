{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/soumyacs/sentiment-analysis-naive-bayes?scriptVersionId=84814787\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-09T15:03:47.354804Z","iopub.execute_input":"2022-01-09T15:03:47.355192Z","iopub.status.idle":"2022-01-09T15:03:47.380796Z","shell.execute_reply.started":"2022-01-09T15:03:47.355099Z","shell.execute_reply":"2022-01-09T15:03:47.380146Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Only need the tweets and associated sentiment\ntweets_df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_train.csv', encoding='latin-1')\ntweets_df = tweets_df[['OriginalTweet', 'Sentiment']]\n\ntest_df = pd.read_csv('../input/covid-19-nlp-text-classification/Corona_NLP_test.csv')\ntest_df = test_df[['OriginalTweet', 'Sentiment']]","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:47.382097Z","iopub.execute_input":"2022-01-09T15:03:47.382483Z","iopub.status.idle":"2022-01-09T15:03:47.745328Z","shell.execute_reply.started":"2022-01-09T15:03:47.382449Z","shell.execute_reply":"2022-01-09T15:03:47.744462Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:47.748108Z","iopub.execute_input":"2022-01-09T15:03:47.748644Z","iopub.status.idle":"2022-01-09T15:03:47.770964Z","shell.execute_reply.started":"2022-01-09T15:03:47.748597Z","shell.execute_reply":"2022-01-09T15:03:47.770313Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"                                          OriginalTweet           Sentiment\n0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n1     When I couldn't find hand sanitizer at Fred Me...            Positive\n2     Find out how you can protect yourself and love...  Extremely Positive\n3     #Panic buying hits #NewYork City as anxious sh...            Negative\n4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n...                                                 ...                 ...\n3793  Meanwhile In A Supermarket in Israel -- People...            Positive\n3794  Did you panic buy a lot of non-perishable item...            Negative\n3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral\n3796  Gov need to do somethings instead of biar je r...  Extremely Negative\n3797  I and @ForestandPaper members are committed to...  Extremely Positive\n\n[3798 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>OriginalTweet</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Find out how you can protect yourself and love...</td>\n      <td>Extremely Positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3793</th>\n      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3794</th>\n      <td>Did you panic buy a lot of non-perishable item...</td>\n      <td>Negative</td>\n    </tr>\n    <tr>\n      <th>3795</th>\n      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3796</th>\n      <td>Gov need to do somethings instead of biar je r...</td>\n      <td>Extremely Negative</td>\n    </tr>\n    <tr>\n      <th>3797</th>\n      <td>I and @ForestandPaper members are committed to...</td>\n      <td>Extremely Positive</td>\n    </tr>\n  </tbody>\n</table>\n<p>3798 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Check for null values\nfor column in tweets_df.columns:\n    print(tweets_df[column].isnull().value_counts())\nprint()  \nfor column in test_df.columns:\n    print(test_df[column].isnull().value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:47.774024Z","iopub.execute_input":"2022-01-09T15:03:47.774397Z","iopub.status.idle":"2022-01-09T15:03:47.802667Z","shell.execute_reply.started":"2022-01-09T15:03:47.774352Z","shell.execute_reply":"2022-01-09T15:03:47.802022Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"False    41157\nName: OriginalTweet, dtype: int64\nFalse    41157\nName: Sentiment, dtype: int64\n\nFalse    3798\nName: OriginalTweet, dtype: int64\nFalse    3798\nName: Sentiment, dtype: int64\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check for duplicate values\nprint(tweets_df.duplicated().value_counts())\nprint()\nprint(test_df.duplicated().value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:47.803965Z","iopub.execute_input":"2022-01-09T15:03:47.80437Z","iopub.status.idle":"2022-01-09T15:03:47.861031Z","shell.execute_reply.started":"2022-01-09T15:03:47.80434Z","shell.execute_reply":"2022-01-09T15:03:47.860107Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"False    41157\ndtype: int64\n\nFalse    3798\ndtype: int64\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Pre-processing","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords\n#from nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\nimport string\n\nnltk.download('stopwords')\n#ps = PorterStemmer()\nlemmatizer = WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:47.862237Z","iopub.execute_input":"2022-01-09T15:03:47.862481Z","iopub.status.idle":"2022-01-09T15:03:49.703541Z","shell.execute_reply.started":"2022-01-09T15:03:47.862452Z","shell.execute_reply":"2022-01-09T15:03:49.702644Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install pyspellchecker \nfrom spellchecker import SpellChecker\nspell = SpellChecker()","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:03:49.704856Z","iopub.execute_input":"2022-01-09T15:03:49.705318Z","iopub.status.idle":"2022-01-09T15:04:01.518096Z","shell.execute_reply.started":"2022-01-09T15:03:49.705277Z","shell.execute_reply":"2022-01-09T15:04:01.517165Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Collecting pyspellchecker\n  Downloading pyspellchecker-0.6.2-py3-none-any.whl (2.7 MB)\n     |████████████████████████████████| 2.7 MB 594 kB/s            \n\u001b[?25hInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.6.2\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"'''def textClean(text):\n    nopunc = [char.lower() for char in text if char not in string.punctuation]\n    nopunc = ''.join(nopunc)\n    #nodigit = ''.join([char for char in nopunc if not char.isdigit()])\n    tokens = word_tokenize(nopunc)\n    nohttp = [word for word in tokens if word[0:4]!='http']\n    nostop = [word for word in nohttp if word not in stopwords.words('english')]\n    #stemmed = [ps.stem(word) for word in nostop ]\n    lemmatized = [lemmatizer.lemmatize(word) for word in nostop]\n    return lemmatized'''","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.520095Z","iopub.execute_input":"2022-01-09T15:04:01.520456Z","iopub.status.idle":"2022-01-09T15:04:01.528295Z","shell.execute_reply.started":"2022-01-09T15:04:01.520409Z","shell.execute_reply":"2022-01-09T15:04:01.527239Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"\"def textClean(text):\\n    nopunc = [char.lower() for char in text if char not in string.punctuation]\\n    nopunc = ''.join(nopunc)\\n    #nodigit = ''.join([char for char in nopunc if not char.isdigit()])\\n    tokens = word_tokenize(nopunc)\\n    nohttp = [word for word in tokens if word[0:4]!='http']\\n    nostop = [word for word in nohttp if word not in stopwords.words('english')]\\n    #stemmed = [ps.stem(word) for word in nostop ]\\n    lemmatized = [lemmatizer.lemmatize(word) for word in nostop]\\n    return lemmatized\""},"metadata":{}}]},{"cell_type":"code","source":"puncs_ = string.punctuation.replace('@','')\npuncs = puncs_.replace('#','')\npuncs","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.530186Z","iopub.execute_input":"2022-01-09T15:04:01.530512Z","iopub.status.idle":"2022-01-09T15:04:01.544098Z","shell.execute_reply.started":"2022-01-09T15:04:01.53046Z","shell.execute_reply":"2022-01-09T15:04:01.543387Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~'"},"metadata":{}}]},{"cell_type":"code","source":"s = '           @ the springs theatre httpstcoaertookvav'\nmytext = \" \".join(s.split(\"  \"))\nmytext","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.547002Z","iopub.execute_input":"2022-01-09T15:04:01.547249Z","iopub.status.idle":"2022-01-09T15:04:01.557938Z","shell.execute_reply.started":"2022-01-09T15:04:01.547221Z","shell.execute_reply":"2022-01-09T15:04:01.557188Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"'      @ the springs theatre httpstcoaertookvav'"},"metadata":{}}]},{"cell_type":"code","source":"def textClean(text):\n    # convert to lowercase\n    lower = [char.lower() for char in text if char not in puncs]\n    lower = ''.join(lower)\n    lower = ' '.join(lower.split())\n    \n    # delete @mentions and #tags\n    for char in lower:\n        if lower.find('@')==-1 and lower.find('#')==-1: # break loop once @ and # is over\n            break\n        if (char=='@' or char=='#'):\n            try:\n                char_index = lower.index(char)\n            except ValueError:\n                #print(lower)\n                break\n            del_word = ''\n            while char not in string.whitespace:\n                del_word = del_word+lower[char_index]\n                char_index = char_index + 1\n                try:\n                    char = lower[char_index] #trying for indexerror incase it is the last character of string\n                except IndexError:\n                    char = ' '\n                except:\n                    print(\"Something else went wrong\")\n            lower = lower.replace(del_word,'',1)\n    lower = [char for char in lower if char not in string.punctuation and char not in string.digits]\n    lower = ''.join(lower)\n    \n    tokens = word_tokenize(lower)\n    nohttp = [word for word in tokens if word[0:4]!='http']\n    nostop = [word for word in nohttp if word not in stopwords.words('english')]\n    return nostop","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.558998Z","iopub.execute_input":"2022-01-09T15:04:01.559549Z","iopub.status.idle":"2022-01-09T15:04:01.573181Z","shell.execute_reply.started":"2022-01-09T15:04:01.559505Z","shell.execute_reply":"2022-01-09T15:04:01.572321Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"#print(tweets_df.OriginalTweet[0:10])\n#tweets_df.OriginalTweet[0:10].apply(textClean)\ntemp_list = tweets_df.OriginalTweet[0:10].apply(textClean)\nfor each_list in temp_list:\n    print(each_list)#for word in each_list:","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.574743Z","iopub.execute_input":"2022-01-09T15:04:01.57513Z","iopub.status.idle":"2022-01-09T15:04:01.652005Z","shell.execute_reply.started":"2022-01-09T15:04:01.575084Z","shell.execute_reply":"2022-01-09T15:04:01.65107Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"[]\n['advice', 'talk', 'neighbours', 'family', 'exchange', 'phone', 'numbers', 'create', 'contact', 'list', 'phone', 'numbers', 'neighbours', 'schools', 'employer', 'chemist', 'gp', 'set', 'online', 'shopping', 'accounts', 'poss', 'adequate', 'supplies', 'regular', 'meds', 'order']\n['coronavirus', 'australia', 'woolworths', 'give', 'elderly', 'disabled', 'dedicated', 'shopping', 'hours', 'amid', 'covid', 'outbreak']\n['food', 'stock', 'one', 'empty', 'please', 'dont', 'panic', 'enough', 'food', 'everyone', 'take', 'need', 'stay', 'calm', 'stay', 'safe']\n['ready', 'go', 'supermarket', 'outbreak', 'im', 'paranoid', 'food', 'stock', 'litteraly', 'empty', 'serious', 'thing', 'please', 'dont', 'panic', 'causes', 'shortage']\n['news', 'regionâ\\x92s', 'first', 'confirmed', 'covid', 'case', 'came', 'sullivan', 'county', 'last', 'week', 'people', 'flocked', 'area', 'stores', 'purchase', 'cleaning', 'supplies', 'hand', 'sanitizer', 'food', 'toilet', 'paper', 'goods', 'reports']\n['cashier', 'grocery', 'store', 'sharing', 'insights', 'prove', 'credibility', 'commented', 'im', 'civics', 'class', 'know', 'im', 'talking']\n['supermarket', 'today', 'didnt', 'buy', 'toilet', 'paper']\n['due', 'covid', 'retail', 'store', 'classroom', 'atlanta', 'open', 'walkin', 'business', 'classes', 'next', 'two', 'weeks', 'beginning', 'monday', 'march', 'continue', 'process', 'online', 'phone', 'orders', 'normal', 'thank', 'understanding']\n['corona', 'preventionwe', 'stop', 'buy', 'things', 'cash', 'use', 'online', 'payment', 'methods', 'corona', 'spread', 'notes', 'also', 'prefer', 'online', 'shopping', 'home', 'time', 'fight', 'covid']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer(analyzer=textClean)\nmessage = vectorizer.fit_transform(tweets_df['OriginalTweet'])\nmessage.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:04:01.65501Z","iopub.execute_input":"2022-01-09T15:04:01.655264Z","iopub.status.idle":"2022-01-09T15:06:49.575693Z","shell.execute_reply.started":"2022-01-09T15:04:01.655235Z","shell.execute_reply":"2022-01-09T15:06:49.57478Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"(41157, 39097)"},"metadata":{}}]},{"cell_type":"code","source":"#split the data into 80% training and 20% testing\nfrom sklearn.model_selection import train_test_split\nxtrain, xtest, ytrain, ytest = train_test_split(message,tweets_df.Sentiment,test_size=0.20,random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:49.576949Z","iopub.execute_input":"2022-01-09T15:06:49.577166Z","iopub.status.idle":"2022-01-09T15:06:49.593661Z","shell.execute_reply.started":"2022-01-09T15:06:49.577141Z","shell.execute_reply":"2022-01-09T15:06:49.592662Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# create and train the Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB().fit(xtrain, ytrain)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:49.595579Z","iopub.execute_input":"2022-01-09T15:06:49.596502Z","iopub.status.idle":"2022-01-09T15:06:49.788258Z","shell.execute_reply.started":"2022-01-09T15:06:49.596451Z","shell.execute_reply":"2022-01-09T15:06:49.787377Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"print(classifier.predict(xtest))\nprint(ytest.values)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:49.789407Z","iopub.execute_input":"2022-01-09T15:06:49.789623Z","iopub.status.idle":"2022-01-09T15:06:49.799696Z","shell.execute_reply.started":"2022-01-09T15:06:49.789598Z","shell.execute_reply":"2022-01-09T15:06:49.798678Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"['Positive' 'Positive' 'Positive' ... 'Positive' 'Neutral' 'Positive']\n['Neutral' 'Negative' 'Positive' ... 'Neutral' 'Neutral' 'Positive']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on the training data set\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\npred = classifier.predict(xtrain)\nprint(classification_report(ytrain, pred))\nprint()\nprint(\"Confusion Matrix: \\n\", confusion_matrix(ytrain, pred))\nprint(\"Accuracy: \\n\", accuracy_score(ytrain, pred))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:49.80122Z","iopub.execute_input":"2022-01-09T15:06:49.801453Z","iopub.status.idle":"2022-01-09T15:06:51.15755Z","shell.execute_reply.started":"2022-01-09T15:06:49.801425Z","shell.execute_reply":"2022-01-09T15:06:51.156684Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"                    precision    recall  f1-score   support\n\nExtremely Negative       0.88      0.66      0.76      4387\nExtremely Positive       0.83      0.72      0.77      5293\n          Negative       0.70      0.78      0.74      7931\n           Neutral       0.93      0.55      0.69      6187\n          Positive       0.63      0.87      0.73      9127\n\n          accuracy                           0.73     32925\n         macro avg       0.79      0.71      0.74     32925\n      weighted avg       0.77      0.73      0.73     32925\n\n\nConfusion Matrix: \n [[2909   32 1033   36  377]\n [  21 3791  166   20 1295]\n [ 257  152 6180  110 1232]\n [  59  139  887 3372 1730]\n [  64  477  575   99 7912]]\nAccuracy: \n 0.7339104024297646\n","output_type":"stream"}]},{"cell_type":"code","source":"# Evaluating the model on the testing data set\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\npred = classifier.predict(xtest)\nprint(classification_report(ytest, pred))\nprint()\nprint(\"Confusion Matrix: \\n\", confusion_matrix(ytest, pred))\nprint(\"Accuracy: \\n\", accuracy_score(ytest, pred))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:51.159095Z","iopub.execute_input":"2022-01-09T15:06:51.159671Z","iopub.status.idle":"2022-01-09T15:06:51.467951Z","shell.execute_reply.started":"2022-01-09T15:06:51.159625Z","shell.execute_reply":"2022-01-09T15:06:51.466823Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"                    precision    recall  f1-score   support\n\nExtremely Negative       0.59      0.39      0.47      1094\nExtremely Positive       0.56      0.44      0.49      1331\n          Negative       0.44      0.50      0.47      1986\n           Neutral       0.67      0.34      0.45      1526\n          Positive       0.41      0.61      0.49      2295\n\n          accuracy                           0.48      8232\n         macro avg       0.53      0.46      0.47      8232\n      weighted avg       0.51      0.48      0.47      8232\n\n\nConfusion Matrix: \n [[ 422    8  511   26  127]\n [   7  589   78   23  634]\n [ 209   72 1000   81  624]\n [  30   44  313  518  621]\n [  48  336  395  123 1393]]\nAccuracy: \n 0.47643343051506315\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Test Data","metadata":{}},{"cell_type":"code","source":"test_df.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:51.469149Z","iopub.execute_input":"2022-01-09T15:06:51.469449Z","iopub.status.idle":"2022-01-09T15:06:51.47629Z","shell.execute_reply.started":"2022-01-09T15:06:51.4694Z","shell.execute_reply":"2022-01-09T15:06:51.475389Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"(3798, 2)"},"metadata":{}}]},{"cell_type":"code","source":"message2 = vectorizer.transform(test_df['OriginalTweet'])\nmessage2.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:06:51.47802Z","iopub.execute_input":"2022-01-09T15:06:51.478324Z","iopub.status.idle":"2022-01-09T15:07:07.987662Z","shell.execute_reply.started":"2022-01-09T15:06:51.478285Z","shell.execute_reply":"2022-01-09T15:07:07.986722Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"(3798, 39097)"},"metadata":{}}]},{"cell_type":"code","source":"message2","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:07:07.988839Z","iopub.execute_input":"2022-01-09T15:07:07.989094Z","iopub.status.idle":"2022-01-09T15:07:07.995541Z","shell.execute_reply.started":"2022-01-09T15:07:07.989064Z","shell.execute_reply":"2022-01-09T15:07:07.994606Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"<3798x39097 sparse matrix of type '<class 'numpy.int64'>'\n\twith 58205 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"cell_type":"code","source":"print(classifier.predict(message2))\nprint(test_df.Sentiment)","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:07:07.996536Z","iopub.execute_input":"2022-01-09T15:07:07.997098Z","iopub.status.idle":"2022-01-09T15:07:08.013784Z","shell.execute_reply.started":"2022-01-09T15:07:07.997063Z","shell.execute_reply":"2022-01-09T15:07:08.013101Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"['Negative' 'Positive' 'Extremely Positive' ... 'Neutral'\n 'Extremely Negative' 'Positive']\n0       Extremely Negative\n1                 Positive\n2       Extremely Positive\n3                 Negative\n4                  Neutral\n               ...        \n3793              Positive\n3794              Negative\n3795               Neutral\n3796    Extremely Negative\n3797    Extremely Positive\nName: Sentiment, Length: 3798, dtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"pred = classifier.predict(message2)\nprint(classification_report(test_df.Sentiment, pred))\nprint()\nprint(\"Confusion Matrix: \\n\", confusion_matrix(test_df.Sentiment, pred))\nprint(\"Accuracy: \\n\", accuracy_score(test_df.Sentiment, pred))","metadata":{"execution":{"iopub.status.busy":"2022-01-09T15:07:08.014973Z","iopub.execute_input":"2022-01-09T15:07:08.015565Z","iopub.status.idle":"2022-01-09T15:07:08.159022Z","shell.execute_reply.started":"2022-01-09T15:07:08.015526Z","shell.execute_reply":"2022-01-09T15:07:08.15811Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"                    precision    recall  f1-score   support\n\nExtremely Negative       0.59      0.30      0.39       592\nExtremely Positive       0.63      0.35      0.45       599\n          Negative       0.44      0.51      0.47      1041\n           Neutral       0.66      0.21      0.31       619\n          Positive       0.37      0.69      0.48       947\n\n          accuracy                           0.45      3798\n         macro avg       0.54      0.41      0.42      3798\n      weighted avg       0.51      0.45      0.43      3798\n\n\nConfusion Matrix: \n [[175   5 328   4  80]\n [  5 211  34   2 347]\n [ 83  21 529  38 370]\n [  9  15 158 127 310]\n [ 26  84 164  21 652]]\nAccuracy: \n 0.4460242232754081\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}